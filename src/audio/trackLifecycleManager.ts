// Track Lifecycle Manager: å®‰å…¨ãªTrackç”Ÿæˆãƒ»ç ´æ£„ã‚·ã‚¹ãƒ†ãƒ 
// Phase 2: Faust WASMçµ±åˆã‹ã‚‰Trackç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å®Œå…¨çµ±åˆ

import { Track, TrackKind, createGenericTrack, addTrack, removeTrack, listTracks } from './tracks';
import { LogicInput } from './logicInputs';
import { createEffectInstance, EffectInstance } from './effects/effectRegistry';

export interface TrackConfig {
    id?: string;
    name: string;
    kind: TrackKind;
    initialVolume?: number;
    dspConfig?: {
        effectRefId: string;
        parameters?: Record<string, number>;
    };
    logicInputId?: string; // é–¢é€£ä»˜ã‘ã‚‹LogicInput ID
}

export interface TrackCreationResult {
    track: Track;
    effectInstance?: EffectInstance;
    success: boolean;
    error?: string;
}

// ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“å®šæ•°
const FADE_IN_TIME = 0.015; // 15ms
const FADE_OUT_TIME = 0.02;  // 20ms
const CLEANUP_DELAY = 30;    // 30msä½™è£•

export class TrackLifecycleManager {
    private static instance: TrackLifecycleManager;
    private audioContext?: AudioContext;
    private pendingCreations = new Map<string, Promise<TrackCreationResult>>();

    private constructor() { }

    static getInstance(): TrackLifecycleManager {
        if (!TrackLifecycleManager.instance) {
            TrackLifecycleManager.instance = new TrackLifecycleManager();
        }
        return TrackLifecycleManager.instance;
    }

    /**
     * AudioContextã‚’è¨­å®š
     */
    setAudioContext(ctx: AudioContext): void {
        this.audioContext = ctx;
    }

    /**
     * å®‰å…¨ãªTrackç”Ÿæˆï¼ˆã‚¯ãƒªãƒƒã‚¯ãƒã‚¤ã‚ºé˜²æ­¢ï¼‰
     */
    async createTrackSafely(config: TrackConfig): Promise<TrackCreationResult> {
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¤–éƒ¨ã§ setAudioContext å‘¼ã°ã‚Œã¦ã„ãªã„å ´åˆ window.audioCtx ãŒã‚ã‚Œã°åˆ©ç”¨
        if (!this.audioContext && (window as any).audioCtx instanceof AudioContext) {
            this.audioContext = (window as any).audioCtx;
            console.log('[TrackLifecycleManager] Adopted global audioCtx');
        }
        if (!this.audioContext) {
            console.warn('[TrackLifecycleManager] AudioContext not set. Call trackLifecycleManager.setAudioContext(audioCtx) after ensureBaseAudio().');
            return {
                track: null as any,
                success: false,
                error: 'AudioContext not set (call setAudioContext after ensureBaseAudio)'
            };
        }

        // é‡è¤‡ä½œæˆé˜²æ­¢
        const pendingKey = config.id || `${config.kind}_${config.name}`;
        if (this.pendingCreations.has(pendingKey)) {
            console.log(`ğŸ”„ Track creation already pending: ${pendingKey}`);
            return await this.pendingCreations.get(pendingKey)!;
        }

        const creationPromise = this._createTrackInternal(config);
        this.pendingCreations.set(pendingKey, creationPromise);

        try {
            const result = await creationPromise;
            this.pendingCreations.delete(pendingKey);
            return result;
        } catch (error) {
            this.pendingCreations.delete(pendingKey);
            throw error;
        }
    }

    /**
     * å†…éƒ¨Trackç”Ÿæˆå‡¦ç†
     */
    private async _createTrackInternal(config: TrackConfig): Promise<TrackCreationResult> {
        const ctx = this.audioContext!;
        console.log(`ğŸ—ï¸ Creating track: ${config.name} (${config.kind})`);

        try {
            let effectInstance: EffectInstance | undefined;

            // Faust DSPã®å ´åˆã¯EffectInstanceã‚’ä½œæˆ
            if (config.kind === 'faust' && config.dspConfig) {
                console.log(`ğŸ›ï¸ Creating Faust effect: ${config.dspConfig.effectRefId}`);
                effectInstance = await createEffectInstance(config.dspConfig.effectRefId, ctx);

                // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆæœŸå€¤è¨­å®š
                if (config.dspConfig.parameters && effectInstance.controller) {
                    for (const [param, value] of Object.entries(config.dspConfig.parameters)) {
                        effectInstance.controller.setParam(param, value);
                    }
                }
            }

            // Trackä½œæˆ
            const track = createGenericTrack({
                id: config.id,
                name: config.name,
                kind: config.kind,
                audioContext: ctx,
                effectInstance
            });

            // åˆæœŸéŸ³é‡è¨­å®šï¼ˆç„¡éŸ³ã‹ã‚‰é–‹å§‹ï¼‰
            track.volumeGain.gain.setValueAtTime(0, ctx.currentTime);
            track.userVolume = config.initialVolume ?? 1;

            // Trackã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            addTrack(track);

            // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ã«ã‚ˆã‚‹å®‰å…¨ãªéŸ³å£°é–‹å§‹
            await this._fadeInTrack(track);

            console.log(`âœ… Track created successfully: ${track.id}`);

            return {
                track,
                effectInstance,
                success: true
            };

        } catch (error) {
            console.error(`âŒ Track creation failed:`, error);
            return {
                track: null as any,
                success: false,
                error: `Track creation failed: ${error}`
            };
        }
    }

    /**
     * Trackå®‰å…¨ãªãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
     */
    private async _fadeInTrack(track: Track): Promise<void> {
        const ctx = this.audioContext!;
        const targetVolume = track.userVolume ?? 1;

        // LinearRampã§ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
        track.volumeGain.gain.linearRampToValueAtTime(
            targetVolume,
            ctx.currentTime + FADE_IN_TIME
        );

        console.log(`ğŸµ Track ${track.id} fading in to volume ${targetVolume}`);

        // ãƒ•ã‚§ãƒ¼ãƒ‰å®Œäº†ã¾ã§å¾…æ©Ÿ
        return new Promise(resolve => {
            setTimeout(resolve, FADE_IN_TIME * 1000 + 5);
        });
    }

    /**
     * Trackå®‰å…¨ãªç ´æ£„ï¼ˆãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
     */
    async dismissTrackSafely(trackId: string): Promise<boolean> {
        if (!this.audioContext) {
            console.warn('âš ï¸ AudioContext not available for track dismissal');
            return false;
        }

        const track = listTracks().find(t => t.id === trackId);
        if (!track) {
            console.warn(`âš ï¸ Track not found: ${trackId}`);
            return false;
        }

        console.log(`ğŸ—‘ï¸ Dismissing track safely: ${trackId}`);

        try {
            // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
            await this._fadeOutTrack(track);

            // Trackå‰Šé™¤
            removeTrack(trackId);

            // é–¢é€£LogicInputã®trackIdè§£é™¤
            this._unlinkLogicInput(trackId);

            console.log(`âœ… Track dismissed successfully: ${trackId}`);
            return true;

        } catch (error) {
            console.error(`âŒ Track dismissal failed:`, error);
            return false;
        }
    }

    /**
     * Trackå®‰å…¨ãªãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
     */
    private async _fadeOutTrack(track: Track): Promise<void> {
        const ctx = this.audioContext!;

        // LinearRampã§ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
        track.volumeGain.gain.linearRampToValueAtTime(
            0,
            ctx.currentTime + FADE_OUT_TIME
        );

        console.log(`ğŸ”‡ Track ${track.id} fading out`);

        // ãƒ•ã‚§ãƒ¼ãƒ‰å®Œäº†ã¾ã§å¾…æ©Ÿ
        return new Promise(resolve => {
            setTimeout(resolve, FADE_OUT_TIME * 1000 + CLEANUP_DELAY);
        });
    }

    /**
     * LogicInputã¨Trackã®é€£æº
     */
    linkLogicInputToTrack(logicInputId: string, trackId: string): void {
        console.log(`ğŸ”— Linking LogicInput ${logicInputId} to Track ${trackId}`);

        // LogicInputManagerãŒã‚ã‚Œã°trackIdã‚’è¨­å®š
        if (window.logicInputManagerInstance) {
            window.logicInputManagerInstance.setTrackId(logicInputId, trackId);
        }

        // ã‚¤ãƒ™ãƒ³ãƒˆç™ºç«
        document.dispatchEvent(new CustomEvent('logic-input-track-linked', {
            detail: { logicInputId, trackId }
        }));
    }

    /**
     * LogicInputã¨Trackã®é€£æºè§£é™¤
     */
    private _unlinkLogicInput(trackId: string): void {
        if (window.logicInputManagerInstance) {
            const logicInputs = window.logicInputManagerInstance.list();
            const linkedInput = logicInputs.find((input: LogicInput) => input.trackId === trackId);

            if (linkedInput) {
                console.log(`ğŸ”“ Unlinking LogicInput ${linkedInput.id} from Track ${trackId}`);
                window.logicInputManagerInstance.setTrackId(linkedInput.id, null);

                document.dispatchEvent(new CustomEvent('logic-input-track-unlinked', {
                    detail: { logicInputId: linkedInput.id, trackId }
                }));
            }
        }
    }

    /**
     * Faustã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‹ã‚‰Trackã‚’è‡ªå‹•ä½œæˆ
     */
    async createTrackFromEffect(effectRefId: string, config?: Partial<TrackConfig>): Promise<TrackCreationResult> {
        const trackConfig: TrackConfig = {
            name: config?.name || `${effectRefId} Track`,
            kind: 'faust',
            initialVolume: config?.initialVolume || 1,
            dspConfig: {
                effectRefId,
                parameters: config?.dspConfig?.parameters
            },
            logicInputId: config?.logicInputId,
            ...config
        };

        return await this.createTrackSafely(trackConfig);
    }

    /**
     * LogicInputã‹ã‚‰Trackã‚’è‡ªå‹•ä½œæˆï¼ˆãƒã‚¤ã‚¯ç­‰ï¼‰
     */
    async createMicTrackFromLogicInput(logicInput: LogicInput): Promise<TrackCreationResult> {
        if (!this.audioContext) {
            return {
                track: null as any,
                success: false,
                error: 'AudioContext not available'
            };
        }

        try {
            // MicTrackç”¨ã®è¨­å®š
            const trackConfig: TrackConfig = {
                name: logicInput.label || `Input ${logicInput.id}`,
                kind: 'mic',
                initialVolume: logicInput.gain || 1,
                logicInputId: logicInput.id
            };

            // æ±ç”¨ä½œæˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ï¼ˆå…¥åŠ›ãƒãƒ¼ãƒ‰ã¯å¾Œã§æ¥ç¶šï¼‰
            const result = await this.createTrackSafely(trackConfig);

            // æˆåŠŸã—ãŸå ´åˆã¯LogicInputã¨ãƒªãƒ³ã‚¯
            if (result.success) {
                this.linkLogicInputToTrack(logicInput.id, result.track.id);
            }

            return result;
        } catch (error) {
            console.error(`âŒ Mic track creation failed:`, error);
            return {
                track: null as any,
                success: false,
                error: `Mic track creation failed: ${error}`
            };
        }
    }

    /**
     * çµ±è¨ˆæƒ…å ±å–å¾—
     */
    getStats(): { totalTracks: number; pendingCreations: number; tracksByKind: Record<TrackKind, number> } {
        const tracks = listTracks();
        const tracksByKind = tracks.reduce((acc, track) => {
            acc[track.kind] = (acc[track.kind] || 0) + 1;
            return acc;
        }, {} as Record<TrackKind, number>);

        return {
            totalTracks: tracks.length,
            pendingCreations: this.pendingCreations.size,
            tracksByKind
        };
    }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const trackLifecycleManager = TrackLifecycleManager.getInstance();

// ã‚°ãƒ­ãƒ¼ãƒãƒ«å…¬é–‹ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
declare global {
    interface Window {
        trackLifecycleManager: TrackLifecycleManager;
    }
}

window.trackLifecycleManager = trackLifecycleManager;

console.log('ğŸš€ Track Lifecycle Manager loaded');
